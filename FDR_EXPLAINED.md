# Understanding False Discovery Rate (FDR) Results

## Quick Summary

**The Bottom Line**: Your k-mer analysis has **excellent specificity** (FDR < 0.2%), but sequencing errors will cause **read loss** (19-34% depending on k-mer size).

---

## What is FDR?

**False Discovery Rate (FDR)** = FP / (FP + TP)

- **FP** (False Positives): K-mers with errors that incorrectly match the WRONG database
- **TP** (True Positives): K-mers with errors that correctly match the RIGHT database
- **FDR**: Among all positive discoveries (matches to a database), what percentage are false?

This is the **gold standard metric** in bioinformatics for assessing the reliability of discoveries.

---

## Your Results Explained

### The Numbers (for k=21, ARMS markers):

When a k-mer gets a sequencing error, here's what happens:

| Outcome | Percentage | What it means |
|---------|-----------|---------------|
| **Novel k-mer** (not in any database) | **99.20%** | Read is LOST (can't use it) |
| **True Positive** (still matches correct database) | **0.057%** | Read is still USABLE âœ“ |
| **False Positive** (matches wrong database) | **0.743%** | Read gives WRONG answer âœ— |

### Two Types of FDR:

#### 1. **Conditional FDR** (among k-mers that still match a database)

```
Conditional FDR = FP / (FP + TP)
                = 0.743% / (0.743% + 0.057%)
                = 0.743% / 0.800%
                = 92.9%
```

**What this means**: Among the tiny fraction (0.8%) of error-containing k-mers that still match a database, **93% match the wrong one!**

This sounds alarming, but it's only among those 0.8% that survive at all.

#### 2. **Absolute FDR** (among ALL k-mers)

```
Absolute FDR = (% with errors) Ã— (% that become FP)
             = 19.13% Ã— 0.743%
             = 0.14%
```

**What this means**: Among ALL k-mers, only **0.14% become false positives**. This is excellent!

---

## Visual Explanation

Let's trace what happens to 100,000 k-mers with 1% per-base error rate:

```
100,000 k-mers
    â†“
    â”œâ”€ 80,867 k-mers (81%) â†’ No errors â†’ âœ“ USABLE
    â”‚
    â””â”€ 19,133 k-mers (19%) â†’ Have errors
           â†“
           â”œâ”€ 18,991 k-mers (99.20%) â†’ Novel (not in any DB) â†’ âœ— READ LOST
           â”‚
           â”œâ”€ 11 k-mers (0.057%) â†’ Still match correct DB â†’ âœ“ USABLE (TP)
           â”‚
           â””â”€ 142 k-mers (0.743%) â†’ Match wrong DB â†’ âœ— FALSE POSITIVE (FP)
```

**Final tally out of 100,000 k-mers:**
- âœ“ **Usable**: 80,878 (81%)
- âœ— **Lost**: 18,991 (19%)
- âœ— **False positives**: 142 (0.14%)

**Conditional FDR**: FP / (FP + TP) = 142 / (142 + 11) = **92.8%**
**Absolute FDR**: 142 / 100,000 = **0.14%**

---

## Why is This Happening?

### The Biology/Sequencing:
1. ONT sequencing has ~1% error rate per base
2. A k=21 k-mer has 21 bases
3. Probability of â‰¥1 error = 1 - (0.99)^21 = **19%**

### The Mathematics:
4. Most k-mers are unique (not shared between databases)
5. A random base change creates a k-mer that's unlikely to exist in ANY database
6. **Result**: 99% of errors create "novel" k-mers

### The Trade-off:
- âœ… **Good news**: Very few false positives (high specificity)
- âŒ **Bad news**: Lots of read loss (reduced sensitivity)

---

## Comparison Across K-mer Sizes

### Conditional FDR (among k-mers WITH errors that match a database):

| K-mer | ARMS Conditional FDR | CEN Conditional FDR |
|-------|----------------------|---------------------|
| k=21  | 93.11%               | 62.93%              |
| k=25  | 93.57%               | 59.16%              |
| k=31  | 92.91%               | 55.68%              |
| k=35  | 93.93%               | 49.44%              |
| k=41  | 93.79%               | 45.07%              |

**Pattern**: CEN markers have lower FDR because they're more error-tolerant (higher sequence similarity between haplotypes).

### Absolute FDR (all k-mers):

All k-mer sizes: **<0.2%** âœ“ Excellent!

### Read Retention:

| K-mer | Retention | Lost to Errors |
|-------|-----------|----------------|
| k=21  | 81.10%    | 18.90%         |
| k=25  | 77.93%    | 22.07%         |
| k=31  | 73.36%    | 26.64%         |
| k=35  | 70.47%    | 29.53%         |
| k=41  | 66.34%    | 33.66%         |

**Pattern**: Longer k-mers have more bases â†’ higher probability of â‰¥1 error â†’ more read loss

---

## What This Means for Your Research

### âœ… Trust Your Positive Calls

When your analysis says "this read matches database X", you can be **99.86% confident** it's correct (FDR = 0.14%).

### ðŸ“‰ But Expect Read Loss

You'll lose 19-34% of your reads depending on k-mer size:
- **k=21**: Lose 19% (best retention)
- **k=41**: Lose 34% (worst retention)

### ðŸŽ¯ Optimize for Your Use Case

**If you prioritize:**
- **Sensitivity** (keeping more reads) â†’ Choose **k=21**
- **Balance** (moderate retention + more markers) â†’ Choose **k=31**
- **Maximum markers** (at cost of retention) â†’ Choose **k=41**

All have excellent specificity (FDR < 0.2%)!

---

## Comparison to Other Studies

### What's considered "good" FDR?

| Field | Acceptable FDR |
|-------|---------------|
| RNA-seq differential expression | <5% |
| ChIP-seq peak calling | <5-10% |
| GWAS (genome-wide association) | <5% |
| Proteomics | <1% |
| **Your k-mer analysis** | **<0.2%** âœ“ Excellent! |

Your analysis has **FDR 25x better** than typical thresholds!

---

## Technical Details

### How FDR was Calculated

For each k-mer size (21, 25, 31, 35, 41):
1. Sampled 100,000 k-mers from each database (20 databases total)
2. Introduced errors using Bernoulli distribution (1% per-base)
3. Tested each mutated k-mer against ALL databases
4. Classified outcomes:
   - **TP**: Matches original database
   - **FP**: Matches different database
   - **Novel**: Doesn't match any database
   - **Ambiguous**: Matches multiple databases
5. Calculated FDR = FP / (FP + TP)

### Why 1% Error Rate?

This simulates **Oxford Nanopore R9** chemistry:
- R9.4.1: ~3-5% error rate (raw reads)
- After basecalling: ~1% error rate (typical)
- R10.4+: <1% error rate (newer chemistry)

If using R10.4+ data, your retention will be even better!

---

## Frequently Asked Questions

### Q1: Why is conditional FDR so high if specificity is excellent?

**A**: Because the denominator (TP + FP) is tiny! Only 0.8% of error-containing k-mers match any database at all. Among that tiny fraction, most are false positives. But 0.8% of 19% = 0.15% of all k-mers, which is excellent.

Think of it like this:
- 1000 k-mers with errors
- 992 disappear (novel - don't match ANY database) â†’ Read lost
- 8 remain (match at least one database)
  - Of those 8: **1 is correct (TP)** and **7 are wrong (FP)**
- Conditional FDR = FP/(FP+TP) = 7/(7+1) = 7/8 = 87.5% (high!)
- Absolute FDR = FP/Total = 7/1000 = 0.7% (low!)

### Q2: Should I be worried about the high conditional FDR?

**A**: No! Focus on **absolute FDR** (<0.2%). That's what matters for your final results.

### Q3: Can I reduce read loss?

**A**: Yes!
1. Use shorter k-mers (k=21 vs k=41): 81% vs 66% retention
2. Use higher-quality basecalling (R10.4 vs R9)
3. Filter low-quality reads before k-mer analysis
4. Use error correction tools (e.g., Medaka, Canu)

### Q4: Why do CEN markers have lower FDR than ARMS?

**A**: CEN (centromere) regions have higher sequence similarity between Col-0 and Ler-0 haplotypes. This means:
- Errors are more likely to still match the correct database
- Higher TP rate
- Lower FDR = FP / (FP + TP)

ARMS (chromosome arms) have more divergence â†’ k-mers are more unique â†’ errors create novel k-mers.

### Q5: Which k-mer size should I use?

Based on FDR alone: **All are excellent** (all <0.2%)!

Choose based on **read retention**:
- **k=21**: Best retention (81%) - recommended for ONT R9
- **k=31**: Balanced (73%) - recommended for general use
- **k=41**: Most markers but lowest retention (66%)

---

## Statistical Interpretation

### Power Analysis

With 1 million ONT reads:

| K-mer | Usable Reads | Lost Reads | False Positives | True Positives |
|-------|--------------|------------|-----------------|----------------|
| k=21  | 811,028      | 188,972    | 1,134           | 809,894        |
| k=31  | 733,577      | 266,423    | 1,189           | 732,388        |
| k=41  | 663,443      | 336,557    | 1,242           | 662,201        |

**Interpretation**:
- You'll detect ~660K-810K real events (TP)
- You'll have ~1,100-1,200 false calls (FP)
- FDR = ~0.14-0.19% (excellent!)
- But k=21 gives you **147,000 more usable reads** than k=41

---

## Conclusion

Your k-mer marker analysis has:

âœ… **Excellent specificity**: FDR < 0.2% (better than typical 5% threshold)
âœ… **Reliable positive calls**: 99.86% of matches are correct
âš ï¸ **Moderate read loss**: 19-34% (inherent to k-mer + ONT errors)

**Recommendation**:
- Use **k=21** to maximize read retention (81%) while maintaining excellent FDR
- Use **k=31** for balanced approach (73% retention, more markers)
- All k-mer sizes have trustworthy results (FDR < 0.2%)

**The high conditional FDR is NOT a problem** - it's actually evidence that your approach is highly specific! Errors don't create false positives; they create read loss.

---

## References

1. Benjamini & Hochberg (1995). "Controlling the False Discovery Rate". Journal of the Royal Statistical Society.
2. Storey & Tibshirani (2003). "Statistical significance for genomewide studies". PNAS.
3. Oxford Nanopore Technologies (2024). "R10.4.1 Accuracy Data".

---

**For more details, see**:
- `RESULTS_FIGURES.md` - Visual documentation of all figures
- `ANALYSIS_SUMMARY.md` - Complete results summary
- `02_cross_contamination.py` - FDR calculation code

**Last Updated**: December 4, 2025
